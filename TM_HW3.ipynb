{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "Jeff Corbin<br>\n",
    "BIA 6304 Text Mining<br>\n",
    "Fall A 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents:\n",
    "\n",
    "1. [General Business Context](#1.-General-Business-Context)\n",
    "2. [Data](#2.-Data)\n",
    "3. [EDA](#3.-EDA)\n",
    "4. [Preprocessing](#4.-Preprocessing)\n",
    "5. [Sentiment Analysis](#5.-Sentiment-Analysis)\n",
    "6. [Summary](#6.-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. General Business Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: The overall goal of the company is to improve content on their fantasy football analytics website to attract more opportunity to convert readers into premium subscription members.\n",
    "\n",
    "**Question 1**: What are the top tokens being used today on Twitter for the topic of fantasy football?\n",
    "\n",
    "**Question 2**: How are trending players, if any, being perceived today on Twitter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are potentially multiple datasets that will be analyzed daily to answer each of our business questions.\n",
    "\n",
    "The first datset contains the most recent 500 tweets tagged with the topic '#FantasyFootball' and is composed of:<br>\n",
    "\n",
    " - newtext: 'Clean' version of the text of the tweet.\n",
    " - tweetCreated: The date the tweet was created on Twitter.\n",
    "\n",
    "The additional dataset(s) are contingent on the daily analysis of the first dataset to discover if there are any trending players to perform sentiment analysis on for the purpose of answering our second question. Each identified trending player would be searched on Twitter to create a dataset of tweets that contain the player's name and the word 'fantasy'. The additional dataset(s) will contain the same variables as our first dataset.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up my environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "#my Twitter app keys and tokens\n",
    "consumer_key =  'tiyduI4E6rxLu1kKPksdadmtO'\n",
    "consumer_secret = 'LB1Emwlqw8Gs9C20eeFjK7v2CqztlwVUiCa2a3E6PxblxdlbUP'\n",
    "access_token = '354548618-iEO3MJBZewHkKfsUz9y81S9cIbipKAI68zTuUBRr'\n",
    "access_secret = '1G7UHF1dSSiVAW1MVcqy0EI2mlhpFPYlAIsTztaaF2EZd'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 1 - #FantasyFootball**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#defining my search results as a list\n",
    "results = []\n",
    "\n",
    "#searching tweets for most recent 500 items about the topic of fantasy football\n",
    "for tweet in tweepy.Cursor(api.search, q='%23FantasyFootball').items(500):\n",
    "    results.append(tweet)\n",
    "\n",
    "#verifying the number of items returned is 500\n",
    "print(type(results))\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to convert my list of tweets into a pandas dataframe containing my chosen fields\n",
    "def toDataFrame(tweets):\n",
    "\n",
    "    DataSet = pd.DataFrame()\n",
    "\n",
    "    DataSet['tweetText'] = [tweet.text for tweet in tweets]\n",
    "    DataSet['tweetCreated'] = [tweet.created_at for tweet in tweets]\n",
    "\n",
    "    return DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing my tweets list to the above function to create a dataframe\n",
    "fantasy_tweets = toDataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "try:\n",
    "    # UCS-4\n",
    "    highpoints = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
    "except re.error:\n",
    "    # UCS-2\n",
    "    highpoints = re.compile(u'([\\u2600-\\u27BF])|([\\uD83C][\\uDF00-\\uDFFF])|([\\uD83D][\\uDC00-\\uDE4F])|([\\uD83D][\\uDE80-\\uDEFF])')\n",
    "\n",
    "decode_text = re.compile(u'(?<!&)#(\\w|(?:[\\xA9\\xAE\\u203C\\u2049\\u2122\\u2139\\u2194-\\u2199\\u21A9\\u21AA\\u231A\\u231B\\u2328\\u2388\\u23CF\\u23E9-\\u23F3\\u23F8-\\u23FA\\u24C2\\u25AA\\u25AB\\u25B6\\u25C0\\u25FB-\\u25FE\\u2600-\\u2604\\u260E\\u2611\\u2614\\u2615\\u2618\\u261D\\u2620\\u2622\\u2623\\u2626\\u262A\\u262E\\u262F\\u2638-\\u263A\\u2648-\\u2653\\u2660\\u2663\\u2665\\u2666\\u2668\\u267B\\u267F\\u2692-\\u2694\\u2696\\u2697\\u2699\\u269B\\u269C\\u26A0\\u26A1\\u26AA\\u26AB\\u26B0\\u26B1\\u26BD\\u26BE\\u26C4\\u26C5\\u26C8\\u26CE\\u26CF\\u26D1\\u26D3\\u26D4\\u26E9\\u26EA\\u26F0-\\u26F5\\u26F7-\\u26FA\\u26FD\\u2702\\u2705\\u2708-\\u270D\\u270F\\u2712\\u2714\\u2716\\u271D\\u2721\\u2728\\u2733\\u2734\\u2744\\u2747\\u274C\\u274E\\u2753-\\u2755\\u2757\\u2763\\u2764\\u2795-\\u2797\\u27A1\\u27B0\\u27BF\\u2934\\u2935\\u2B05-\\u2B07\\u2B1B\\u2B1C\\u2B50\\u2B55\\u3030\\u303D\\u3297\\u3299]|\\uD83C[\\uDC04\\uDCCF\\uDD70\\uDD71\\uDD7E\\uDD7F\\uDD8E\\uDD91-\\uDD9A\\uDE01\\uDE02\\uDE1A\\uDE2F\\uDE32-\\uDE3A\\uDE50\\uDE51\\uDF00-\\uDF21\\uDF24-\\uDF93\\uDF96\\uDF97\\uDF99-\\uDF9B\\uDF9E-\\uDFF0\\uDFF3-\\uDFF5\\uDFF7-\\uDFFF]|\\uD83D[\\uDC00-\\uDCFD\\uDCFF-\\uDD3D\\uDD49-\\uDD4E\\uDD50-\\uDD67\\uDD6F\\uDD70\\uDD73-\\uDD79\\uDD87\\uDD8A-\\uDD8D\\uDD90\\uDD95\\uDD96\\uDDA5\\uDDA8\\uDDB1\\uDDB2\\uDDBC\\uDDC2-\\uDDC4\\uDDD1-\\uDDD3\\uDDDC-\\uDDDE\\uDDE1\\uDDE3\\uDDEF\\uDDF3\\uDDFA-\\uDE4F\\uDE80-\\uDEC5\\uDECB-\\uDED0\\uDEE0-\\uDEE5\\uDEE9\\uDEEB\\uDEEC\\uDEF0\\uDEF3]|\\uD83E[\\uDD10-\\uDD18\\uDD80-\\uDD84\\uDDC0]|(?:0\\u20E3|1\\u20E3|2\\u20E3|3\\u20E3|4\\u20E3|5\\u20E3|6\\u20E3|7\\u20E3|8\\u20E3|9\\u20E3|#\\u20E3|\\\\*\\u20E3|\\uD83C(?:\\uDDE6\\uD83C(?:\\uDDEB|\\uDDFD|\\uDDF1|\\uDDF8|\\uDDE9|\\uDDF4|\\uDDEE|\\uDDF6|\\uDDEC|\\uDDF7|\\uDDF2|\\uDDFC|\\uDDE8|\\uDDFA|\\uDDF9|\\uDDFF|\\uDDEA)|\\uDDE7\\uD83C(?:\\uDDF8|\\uDDED|\\uDDE9|\\uDDE7|\\uDDFE|\\uDDEA|\\uDDFF|\\uDDEF|\\uDDF2|\\uDDF9|\\uDDF4|\\uDDE6|\\uDDFC|\\uDDFB|\\uDDF7|\\uDDF3|\\uDDEC|\\uDDEB|\\uDDEE|\\uDDF6|\\uDDF1)|\\uDDE8\\uD83C(?:\\uDDF2|\\uDDE6|\\uDDFB|\\uDDEB|\\uDDF1|\\uDDF3|\\uDDFD|\\uDDF5|\\uDDE8|\\uDDF4|\\uDDEC|\\uDDE9|\\uDDF0|\\uDDF7|\\uDDEE|\\uDDFA|\\uDDFC|\\uDDFE|\\uDDFF|\\uDDED)|\\uDDE9\\uD83C(?:\\uDDFF|\\uDDF0|\\uDDEC|\\uDDEF|\\uDDF2|\\uDDF4|\\uDDEA)|\\uDDEA\\uD83C(?:\\uDDE6|\\uDDE8|\\uDDEC|\\uDDF7|\\uDDEA|\\uDDF9|\\uDDFA|\\uDDF8|\\uDDED)|\\uDDEB\\uD83C(?:\\uDDF0|\\uDDF4|\\uDDEF|\\uDDEE|\\uDDF7|\\uDDF2)|\\uDDEC\\uD83C(?:\\uDDF6|\\uDDEB|\\uDDE6|\\uDDF2|\\uDDEA|\\uDDED|\\uDDEE|\\uDDF7|\\uDDF1|\\uDDE9|\\uDDF5|\\uDDFA|\\uDDF9|\\uDDEC|\\uDDF3|\\uDDFC|\\uDDFE|\\uDDF8|\\uDDE7)|\\uDDED\\uD83C(?:\\uDDF7|\\uDDF9|\\uDDF2|\\uDDF3|\\uDDF0|\\uDDFA)|\\uDDEE\\uD83C(?:\\uDDF4|\\uDDE8|\\uDDF8|\\uDDF3|\\uDDE9|\\uDDF7|\\uDDF6|\\uDDEA|\\uDDF2|\\uDDF1|\\uDDF9)|\\uDDEF\\uD83C(?:\\uDDF2|\\uDDF5|\\uDDEA|\\uDDF4)|\\uDDF0\\uD83C(?:\\uDDED|\\uDDFE|\\uDDF2|\\uDDFF|\\uDDEA|\\uDDEE|\\uDDFC|\\uDDEC|\\uDDF5|\\uDDF7|\\uDDF3)|\\uDDF1\\uD83C(?:\\uDDE6|\\uDDFB|\\uDDE7|\\uDDF8|\\uDDF7|\\uDDFE|\\uDDEE|\\uDDF9|\\uDDFA|\\uDDF0|\\uDDE8)|\\uDDF2\\uD83C(?:\\uDDF4|\\uDDF0|\\uDDEC|\\uDDFC|\\uDDFE|\\uDDFB|\\uDDF1|\\uDDF9|\\uDDED|\\uDDF6|\\uDDF7|\\uDDFA|\\uDDFD|\\uDDE9|\\uDDE8|\\uDDF3|\\uDDEA|\\uDDF8|\\uDDE6|\\uDDFF|\\uDDF2|\\uDDF5|\\uDDEB)|\\uDDF3\\uD83C(?:\\uDDE6|\\uDDF7|\\uDDF5|\\uDDF1|\\uDDE8|\\uDDFF|\\uDDEE|\\uDDEA|\\uDDEC|\\uDDFA|\\uDDEB|\\uDDF4)|\\uDDF4\\uD83C\\uDDF2|\\uDDF5\\uD83C(?:\\uDDEB|\\uDDF0|\\uDDFC|\\uDDF8|\\uDDE6|\\uDDEC|\\uDDFE|\\uDDEA|\\uDDED|\\uDDF3|\\uDDF1|\\uDDF9|\\uDDF7|\\uDDF2)|\\uDDF6\\uD83C\\uDDE6|\\uDDF7\\uD83C(?:\\uDDEA|\\uDDF4|\\uDDFA|\\uDDFC|\\uDDF8)|\\uDDF8\\uD83C(?:\\uDDFB|\\uDDF2|\\uDDF9|\\uDDE6|\\uDDF3|\\uDDE8|\\uDDF1|\\uDDEC|\\uDDFD|\\uDDF0|\\uDDEE|\\uDDE7|\\uDDF4|\\uDDF8|\\uDDED|\\uDDE9|\\uDDF7|\\uDDEF|\\uDDFF|\\uDDEA|\\uDDFE)|\\uDDF9\\uD83C(?:\\uDDE9|\\uDDEB|\\uDDFC|\\uDDEF|\\uDDFF|\\uDDED|\\uDDF1|\\uDDEC|\\uDDF0|\\uDDF4|\\uDDF9|\\uDDE6|\\uDDF3|\\uDDF7|\\uDDF2|\\uDDE8|\\uDDFB)|\\uDDFA\\uD83C(?:\\uDDEC|\\uDDE6|\\uDDF8|\\uDDFE|\\uDDF2|\\uDDFF)|\\uDDFB\\uD83C(?:\\uDDEC|\\uDDE8|\\uDDEE|\\uDDFA|\\uDDE6|\\uDDEA|\\uDDF3)|\\uDDFC\\uD83C(?:\\uDDF8|\\uDDEB)|\\uDDFD\\uD83C\\uDDF0|\\uDDFE\\uD83C(?:\\uDDF9|\\uDDEA)|\\uDDFF\\uD83C(?:\\uDDE6|\\uDDF2|\\uDDFC))))[\\ufe00-\\ufe0f\\u200d]?)+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetText</th>\n",
       "      <th>newtext</th>\n",
       "      <th>tweetCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🚨OVER 6 is a WINNER!!🚨🔥909-350-19🔥#ATS #WeWinW...</td>\n",
       "      <td>OVER 6 is a WINNER!!909-350-19#ATS #WeWinWhenY...</td>\n",
       "      <td>2019-10-10 01:11:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @TheFFRealist: It’s a shame that Noah Fant ...</td>\n",
       "      <td>RT @TheFFRealist: It’s a shame that Noah Fant ...</td>\n",
       "      <td>2019-10-10 01:11:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TheBackRowShow: We bring you the week 6 #I...</td>\n",
       "      <td>RT @TheBackRowShow: We bring you the week 6 #I...</td>\n",
       "      <td>2019-10-10 01:10:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @BaseballGuys: #nfl ARTICLE - 2019: Week 6 ...</td>\n",
       "      <td>RT @BaseballGuys: #nfl ARTICLE - 2019: Week 6 ...</td>\n",
       "      <td>2019-10-10 01:10:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#FantasyFootball #QBRankings Week 6 via @broeh...</td>\n",
       "      <td>#FantasyFootball #QBRankings Week 6 via @broeh...</td>\n",
       "      <td>2019-10-10 01:10:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweetText  \\\n",
       "0  🚨OVER 6 is a WINNER!!🚨🔥909-350-19🔥#ATS #WeWinW...   \n",
       "1  RT @TheFFRealist: It’s a shame that Noah Fant ...   \n",
       "2  RT @TheBackRowShow: We bring you the week 6 #I...   \n",
       "3  RT @BaseballGuys: #nfl ARTICLE - 2019: Week 6 ...   \n",
       "4  #FantasyFootball #QBRankings Week 6 via @broeh...   \n",
       "\n",
       "                                             newtext        tweetCreated  \n",
       "0  OVER 6 is a WINNER!!909-350-19#ATS #WeWinWhenY... 2019-10-10 01:11:24  \n",
       "1  RT @TheFFRealist: It’s a shame that Noah Fant ... 2019-10-10 01:11:09  \n",
       "2  RT @TheBackRowShow: We bring you the week 6 #I... 2019-10-10 01:10:36  \n",
       "3  RT @BaseballGuys: #nfl ARTICLE - 2019: Week 6 ... 2019-10-10 01:10:32  \n",
       "4  #FantasyFootball #QBRankings Week 6 via @broeh... 2019-10-10 01:10:14  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoding unicode to ascii in my dataframe column\n",
    "fantasy_tweets['newtext'] = list(map(lambda x: highpoints.sub(u'',x), fantasy_tweets['tweetText']))\n",
    "\n",
    "#re-ordering the columns to put my 'newtext' closer to the original 'tweetText'\n",
    "column_names = fantasy_tweets.columns.tolist()\n",
    "myorder=[0,2,1]\n",
    "column_names = [column_names[i] for i in myorder]\n",
    "fantasy_tweets = fantasy_tweets[column_names]\n",
    "\n",
    "fantasy_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_tweets.drop(['tweetText'],inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove unwanted text patterns from the tweets\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passed “@[\\w]*” as the pattern to the remove_pattern function - this will remove any word begininning with '@'\n",
    "fantasy_tweets['clean_tweet'] = np.vectorize(remove_pattern)(fantasy_tweets['newtext'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving a copy of today's tweets\n",
    "fantasy_tweets[0:500].to_csv('FantasyFootball_100919.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      "newtext         500 non-null object\n",
      "tweetCreated    500 non-null datetime64[ns]\n",
      "clean_tweet     500 non-null object\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#getting descriptive info about the data\n",
    "fantasy_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newtext</th>\n",
       "      <th>tweetCreated</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVER 6 is a WINNER!!909-350-19#ATS #WeWinWhenY...</td>\n",
       "      <td>2019-10-10 01:11:24</td>\n",
       "      <td>OVER 6 is a WINNER!!909-350-19#ATS #WeWinWhenY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @TheFFRealist: It’s a shame that Noah Fant ...</td>\n",
       "      <td>2019-10-10 01:11:09</td>\n",
       "      <td>RT : It’s a shame that Noah Fant has only had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TheBackRowShow: We bring you the week 6 #I...</td>\n",
       "      <td>2019-10-10 01:10:36</td>\n",
       "      <td>RT : We bring you the week 6 #IDP PRIMER.  Who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @BaseballGuys: #nfl ARTICLE - 2019: Week 6 ...</td>\n",
       "      <td>2019-10-10 01:10:32</td>\n",
       "      <td>RT : #nfl ARTICLE - 2019: Week 6 NFL Gameday M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#FantasyFootball #QBRankings Week 6 via @broeh...</td>\n",
       "      <td>2019-10-10 01:10:14</td>\n",
       "      <td>#FantasyFootball #QBRankings Week 6 via  | #NF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             newtext        tweetCreated  \\\n",
       "0  OVER 6 is a WINNER!!909-350-19#ATS #WeWinWhenY... 2019-10-10 01:11:24   \n",
       "1  RT @TheFFRealist: It’s a shame that Noah Fant ... 2019-10-10 01:11:09   \n",
       "2  RT @TheBackRowShow: We bring you the week 6 #I... 2019-10-10 01:10:36   \n",
       "3  RT @BaseballGuys: #nfl ARTICLE - 2019: Week 6 ... 2019-10-10 01:10:32   \n",
       "4  #FantasyFootball #QBRankings Week 6 via @broeh... 2019-10-10 01:10:14   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  OVER 6 is a WINNER!!909-350-19#ATS #WeWinWhenY...  \n",
       "1  RT : It’s a shame that Noah Fant has only had ...  \n",
       "2  RT : We bring you the week 6 #IDP PRIMER.  Who...  \n",
       "3  RT : #nfl ARTICLE - 2019: Week 6 NFL Gameday M...  \n",
       "4  #FantasyFootball #QBRankings Week 6 via  | #NF...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fantasy_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing additional packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1820)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantasyfootball</th>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https</th>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfl</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantasy</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>football</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantasyfootballadvice</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count\n",
       "fantasyfootball          277\n",
       "rt                       266\n",
       "https                    261\n",
       "co                       249\n",
       "week                     225\n",
       "to                       172\n",
       "the                      164\n",
       "nfl                      124\n",
       "in                       109\n",
       "you                      104\n",
       "this                      89\n",
       "and                       77\n",
       "fantasy                   76\n",
       "football                  74\n",
       "for                       74\n",
       "your                      70\n",
       "my                        69\n",
       "check                     64\n",
       "fantasyfootballadvice     59"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting top 20 tokens for EDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv_def = CountVectorizer(lowercase=True, binary=False) \n",
    "cv_eda = cv_def.fit_transform(fantasy_tweets['newtext'])\n",
    "print(cv_eda.shape)\n",
    "names_eda = cv_def.get_feature_names()   #create list of feature names\n",
    "count_eda = np.sum(cv_eda.toarray(), axis = 0) # add up feature counts \n",
    "count2_eda = count_eda.tolist()  # convert numpy array to list\n",
    "count_eda_df = pd.DataFrame(count2_eda, index = names_eda, columns = ['count']) # create a dataframe from the list\n",
    "count_eda_df.sort_values(['count'], ascending = False)[0:19]  #arrange by count instead of alphabetical (top 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**<br>\n",
    "\n",
    "EDA was performed using some descriptive info on the data as well as counts of the top 20 tokens created from sklearn's countvectorizor. The descriptive info was used to see if there were any null values potentially needing attention, as well as each feature's datatype, and the size of the dataframe. The default settings for the countvectorizor were used in this step to get a general sense of the collection frequency.\n",
    "\n",
    "The EDA helped me identify that there were no null values and that there is some preprocessing needed to get a better sense of meaningful tokens that could potentially be factored into today's website content and social media posts. The counts revealed there are many common stop words that need removed, such as 'and', as well as some custom such as 'https', 'rt', which are more specific to the type of data from tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing nltk package for next steps\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "#create an object storing the default nltk stopwords\n",
    "nltk_stopwords = stopwords.words(\"english\") \n",
    "\n",
    "#create a custom stop words list by adding common industry terms and non-words to the nltk list\n",
    "my_stopwords = nltk_stopwords + [\"rt\", \"https\", \"co\", \"fantasyfootball\", \"nfl\", \n",
    "                                 \"week\", \"amp\",\"episode\",\"points\",\"fantasy\",\"football\",\"team\"\n",
    "                                \"game\",\"league\",\"leagues\",\"win\",\"lose\",\"won\",\"lost\",\"season\",\"espn\",\n",
    "                                 \"article\",\"practice\",\"2019\",\"via\",\"check\",\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1450)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantasyfootballadvice</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suerte</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weeks</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>em</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mundofantasyalrescate</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wr</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rankings</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuller</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jones</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>julio</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wire</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>move</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiver</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sell</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sit</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count\n",
       "fantasyfootballadvice     59\n",
       "get                       50\n",
       "team                      48\n",
       "suerte                    37\n",
       "weeks                     36\n",
       "em                        36\n",
       "mundofantasyalrescate     35\n",
       "make                      34\n",
       "start                     32\n",
       "buy                       29\n",
       "wr                        29\n",
       "right                     28\n",
       "looking                   27\n",
       "new                       25\n",
       "big                       25\n",
       "top                       25\n",
       "rankings                  23\n",
       "fuller                    23\n",
       "jones                     23\n",
       "julio                     22\n",
       "wire                      22\n",
       "move                      22\n",
       "low                       22\n",
       "high                      21\n",
       "waiver                    21\n",
       "help                      21\n",
       "sell                      21\n",
       "back                      21\n",
       "sit                       20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting top 30 tokens after including stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv_stop = CountVectorizer(lowercase=True, binary=False, stop_words = my_stopwords) \n",
    "cv_prep = cv_stop.fit_transform(fantasy_tweets['clean_tweet'])\n",
    "print(cv_prep.shape)\n",
    "names_prep = cv_stop.get_feature_names()   #create list of feature names\n",
    "count_prep = np.sum(cv_prep.toarray(), axis = 0) # add up feature counts\n",
    "count2_prep = count_prep.tolist()  # convert numpy array to list\n",
    "count_prep_df = pd.DataFrame(count2_prep, index = names_prep, columns = ['count']) # create a dataframe from the list\n",
    "count_prep_df.sort_values(['count'], ascending = False)[0:29]  #arrange by count instead of alphabetical (top 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**<br>\n",
    "After excluding common and industry specific stopwords, a more meaningful count vectorizer list of tokens has resulted, giving a sense of which fantasy football topics are trending today as well as at least one player name to look into further. \n",
    "\n",
    "Tokens such as 'start' and 'sit' are indicative that people are starting to look for advice on whether to start or sit certain players for this week's slate of NFL games. The games begin on Thursday night and end on Monday night, so it makes sense that a start/sit article would be best timed around Wednesday or Thursday before the first game of the week. Additionally, tokens of: 'buy', 'sell', 'waiver', 'move', 'rankings', 'looking', and 'help' are all meaningful industry terms for consideration in the type of articles people are looking for the most today.\n",
    "\n",
    "\n",
    "Additionally, we find that two player names have appeared in the top 30 tokens from our search today, identified as the tokens 'julio' and 'fuller'. The question now becomes, how are these players being talked about within the fantasy football context? We will pull two new datasets searching specifically for fantasy tweets mentioning each player, respectively, to perform a sentiment analysis on each to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 2 - Julio Jones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating step 2 in order to pull a new dataset containing tweets specific to any player(s) identified from analysis of Dataset 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "463\n"
     ]
    }
   ],
   "source": [
    "#defining my search results as a list\n",
    "results = []\n",
    "\n",
    "#searching tweets for most recent 500 items about player identified\n",
    "for tweet in tweepy.Cursor(api.search, q='julio fantasy').items(500):\n",
    "    results.append(tweet)\n",
    "\n",
    "#verifying the number of items returned is 500\n",
    "print(type(results))\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to convert my list of tweets into a pandas dataframe containing my chosen fields\n",
    "def toDataFrame(tweets):\n",
    "\n",
    "    DataSet = pd.DataFrame()\n",
    "\n",
    "    DataSet['tweetText'] = [tweet.text for tweet in tweets]\n",
    "    DataSet['tweetCreated'] = [tweet.created_at for tweet in tweets]\n",
    "\n",
    "    return DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing my tweets list to the above function to create a dataframe\n",
    "fantasy_tweets_p1 = toDataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetText</th>\n",
       "      <th>newtext</th>\n",
       "      <th>tweetCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @createArank: Cooper Kupp leads the #NFL in...</td>\n",
       "      <td>RT @createArank: Cooper Kupp leads the #NFL in...</td>\n",
       "      <td>2019-10-10 00:53:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My fantasy teams seeing Julio miss practice: h...</td>\n",
       "      <td>My fantasy teams seeing Julio miss practice: h...</td>\n",
       "      <td>2019-10-10 00:35:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING NFL: Jones was held out of Wednesday'...</td>\n",
       "      <td>BREAKING NFL: Jones was held out of Wednesday'...</td>\n",
       "      <td>2019-10-10 00:34:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offered a guy in my fantasy league Julio for C...</td>\n",
       "      <td>Offered a guy in my fantasy league Julio for C...</td>\n",
       "      <td>2019-10-09 23:48:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me and my dad (who is a huge falcons fan) are ...</td>\n",
       "      <td>Me and my dad (who is a huge falcons fan) are ...</td>\n",
       "      <td>2019-10-09 23:30:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweetText  \\\n",
       "0  RT @createArank: Cooper Kupp leads the #NFL in...   \n",
       "1  My fantasy teams seeing Julio miss practice: h...   \n",
       "2  BREAKING NFL: Jones was held out of Wednesday'...   \n",
       "3  Offered a guy in my fantasy league Julio for C...   \n",
       "4  Me and my dad (who is a huge falcons fan) are ...   \n",
       "\n",
       "                                             newtext        tweetCreated  \n",
       "0  RT @createArank: Cooper Kupp leads the #NFL in... 2019-10-10 00:53:46  \n",
       "1  My fantasy teams seeing Julio miss practice: h... 2019-10-10 00:35:31  \n",
       "2  BREAKING NFL: Jones was held out of Wednesday'... 2019-10-10 00:34:01  \n",
       "3  Offered a guy in my fantasy league Julio for C... 2019-10-09 23:48:38  \n",
       "4  Me and my dad (who is a huge falcons fan) are ... 2019-10-09 23:30:11  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoding unicode to ascii in my dataframe column\n",
    "fantasy_tweets_p1['newtext'] = list(map(lambda x: highpoints.sub(u'',x), fantasy_tweets_p1['tweetText']))\n",
    "\n",
    "#re-ordering the columns to put my 'newtext' closer to the original 'tweetText'\n",
    "column_names = fantasy_tweets_p1.columns.tolist()\n",
    "myorder=[0,2,1]\n",
    "column_names = [column_names[i] for i in myorder]\n",
    "fantasy_tweets_p1 = fantasy_tweets_p1[column_names]\n",
    "\n",
    "fantasy_tweets_p1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_tweets_p1.drop(['tweetText'],inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passed “@[\\w]*” as the pattern to the remove_pattern function - this will remove any word begininning with '@'\n",
    "fantasy_tweets_p1['clean_tweet'] = np.vectorize(remove_pattern)(fantasy_tweets_p1['newtext'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 3 - Will Fuller**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#defining my search results as a list\n",
    "results = []\n",
    "\n",
    "#searching tweets for most recent 500 items about player identified\n",
    "for tweet in tweepy.Cursor(api.search, q='fuller fantasy').items(500):\n",
    "    results.append(tweet)\n",
    "\n",
    "#verifying the number of items returned is 500\n",
    "print(type(results))\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to convert my list of tweets into a pandas dataframe containing my chosen fields\n",
    "def toDataFrame(tweets):\n",
    "\n",
    "    DataSet = pd.DataFrame()\n",
    "\n",
    "    DataSet['tweetText'] = [tweet.text for tweet in tweets]\n",
    "    DataSet['tweetCreated'] = [tweet.created_at for tweet in tweets]\n",
    "\n",
    "    return DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing my tweets list to the above function to create a dataframe\n",
    "fantasy_tweets_p2 = toDataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetText</th>\n",
       "      <th>newtext</th>\n",
       "      <th>tweetCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meu time no fantasy ta lisao\\n\\nBaker/Rivers\\n...</td>\n",
       "      <td>meu time no fantasy ta lisao\\n\\nBaker/Rivers\\n...</td>\n",
       "      <td>2019-10-10 00:26:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @bob_lung: Yes, Will Fuller had a record-br...</td>\n",
       "      <td>RT @bob_lung: Yes, Will Fuller had a record-br...</td>\n",
       "      <td>2019-10-10 00:25:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @DomiNateFF: Not only did Will Fuller put u...</td>\n",
       "      <td>RT @DomiNateFF: Not only did Will Fuller put u...</td>\n",
       "      <td>2019-10-10 00:24:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @NFLResearch: Will Fuller V balled out in W...</td>\n",
       "      <td>RT @NFLResearch: Will Fuller V balled out in W...</td>\n",
       "      <td>2019-10-10 00:18:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sneaky Week 5 Fantasy Football Starts: Jaylen ...</td>\n",
       "      <td>Sneaky Week 5 Fantasy Football Starts: Jaylen ...</td>\n",
       "      <td>2019-10-10 00:12:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweetText  \\\n",
       "0  meu time no fantasy ta lisao\\n\\nBaker/Rivers\\n...   \n",
       "1  RT @bob_lung: Yes, Will Fuller had a record-br...   \n",
       "2  RT @DomiNateFF: Not only did Will Fuller put u...   \n",
       "3  RT @NFLResearch: Will Fuller V balled out in W...   \n",
       "4  Sneaky Week 5 Fantasy Football Starts: Jaylen ...   \n",
       "\n",
       "                                             newtext        tweetCreated  \n",
       "0  meu time no fantasy ta lisao\\n\\nBaker/Rivers\\n... 2019-10-10 00:26:11  \n",
       "1  RT @bob_lung: Yes, Will Fuller had a record-br... 2019-10-10 00:25:40  \n",
       "2  RT @DomiNateFF: Not only did Will Fuller put u... 2019-10-10 00:24:20  \n",
       "3  RT @NFLResearch: Will Fuller V balled out in W... 2019-10-10 00:18:13  \n",
       "4  Sneaky Week 5 Fantasy Football Starts: Jaylen ... 2019-10-10 00:12:14  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoding unicode to ascii in my dataframe column\n",
    "fantasy_tweets_p2['newtext'] = list(map(lambda x: highpoints.sub(u'',x), fantasy_tweets_p2['tweetText']))\n",
    "\n",
    "#re-ordering the columns to put my 'newtext' closer to the original 'tweetText'\n",
    "column_names = fantasy_tweets_p2.columns.tolist()\n",
    "myorder=[0,2,1]\n",
    "column_names = [column_names[i] for i in myorder]\n",
    "fantasy_tweets_p2 = fantasy_tweets_p2[column_names]\n",
    "\n",
    "fantasy_tweets_p2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_tweets_p2.drop(['tweetText'],inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passed “@[\\w]*” as the pattern to the remove_pattern function - this will remove any word begininning with '@'\n",
    "fantasy_tweets_p2['clean_tweet'] = np.vectorize(remove_pattern)(fantasy_tweets_p2['newtext'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining my path for reading in data in next line\n",
    "path = '/Users/jeffcorbin/Downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the afinn object as the afinn sentiment dictionary\n",
    "afinn = {}\n",
    "for line in open(path+\"AFINN-111.txt\"):\n",
    "    tt = line.split('\\t')\n",
    "    afinn.update({tt[0]:int(tt[1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are going for strictly the sum:  add up the positives and \"subtract\" the negatives\n",
    "# defining sentiment labels based on the cumulative total of positives and negatives\n",
    "def afinn_sent(inputstring):\n",
    "    \n",
    "    sentcount =0\n",
    "    for word in inputstring.split():  \n",
    "        if word.rstrip('?:!.,;') in afinn:\n",
    "            sentcount = sentcount + afinn[word.rstrip('?:!.,;')]\n",
    "            \n",
    "    \n",
    "    if (sentcount < 0):\n",
    "        sentiment = 'Negative'\n",
    "    elif (sentcount >0):\n",
    "        sentiment = 'Positive'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending the sentiment labels of the raw data - Julio\n",
    "fantasy_tweets_p1['afinn'] = fantasy_tweets_p1.newtext.apply(lambda x: afinn_sent(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending the sentiment labels of the raw data - Fuller\n",
    "fantasy_tweets_p2['afinn'] = fantasy_tweets_p2.newtext.apply(lambda x: afinn_sent(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>afinn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT : Cooper Kupp leads the #NFL in targets wit...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My fantasy teams seeing Julio miss practice: h...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING NFL: Jones was held out of Wednesday'...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Offered a guy in my fantasy league Julio for C...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me and my dad (who is a huge falcons fan) are ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet     afinn\n",
       "0  RT : Cooper Kupp leads the #NFL in targets wit...   Neutral\n",
       "1  My fantasy teams seeing Julio miss practice: h...  Negative\n",
       "2  BREAKING NFL: Jones was held out of Wednesday'...  Negative\n",
       "3  Offered a guy in my fantasy league Julio for C...   Neutral\n",
       "4  Me and my dad (who is a huge falcons fan) are ...  Positive"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of sentiment labels applied to raw data - Julio\n",
    "fantasy_tweets_p1.iloc[0:5][['clean_tweet','afinn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>afinn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meu time no fantasy ta lisao\\n\\nBaker/Rivers\\n...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT : Yes, Will Fuller had a record-breaking ga...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT : Not only did Will Fuller put up the best ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT : Will Fuller V balled out in Wk 5, scoring...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sneaky Week 5 Fantasy Football Starts: Jaylen ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet     afinn\n",
       "0  meu time no fantasy ta lisao\\n\\nBaker/Rivers\\n...  Negative\n",
       "1  RT : Yes, Will Fuller had a record-breaking ga...   Neutral\n",
       "2  RT : Not only did Will Fuller put up the best ...  Positive\n",
       "3  RT : Will Fuller V balled out in Wk 5, scoring...  Negative\n",
       "4  Sneaky Week 5 Fantasy Football Starts: Jaylen ...   Neutral"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of sentiment labels applied to raw data - Fuller\n",
    "fantasy_tweets_p2.iloc[0:5][['clean_tweet','afinn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define custom color palette for each sentiment label for plotting\n",
    "colors = ['#A8A878',  # Neutral\n",
    "          '#C03028',  # Negative\n",
    "          '#78C850',  # Positive\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julio Jones Sentiment Class Balance\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show class imbalance using seaborn's countplot - Julio\n",
    "import seaborn as sns\n",
    "print('Julio Jones Sentiment Class Balance')\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"afinn\", order=['Neutral','Negative','Positive'], data=fantasy_tweets_p1, palette=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will Fuller Sentiment Class Balance\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show class imbalance using seaborn's countplot - Fuller\n",
    "import seaborn as sns\n",
    "print('Will Fuller Sentiment Class Balance')\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"afinn\", order=['Neutral','Negative','Positive'],data=fantasy_tweets_p2, palette=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object storing the default nltk stopwords\n",
    "nltk_stopwords = stopwords.words(\"english\") \n",
    "\n",
    "#create a custom stop words list for player datasets\n",
    "my_stopwords_1 = nltk_stopwords + [\"rt\", \"https\", \"co\", \"fantasyfootball\", \"nfl\", \n",
    "                                 \"week\", \"amp\",\"episode\",\"points\",\"fantasy\",\"football\",\"team\"\n",
    "                                \"game\",\"league\",\"leagues\",\"win\",\"lose\",\"won\",\"lost\",\"season\",\"espn\",\n",
    "                                 \"article\",\"2019\",\"via\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463, 1269)\n",
      "\n",
      "Julio Jones Tweets - Token Count\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>julio</th>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jones</th>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooper</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allen</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keenan</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wr</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mike</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kupp</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>godwin</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chris</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaders</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ev</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopkins</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "julio      367\n",
       "jones      215\n",
       "cooper     113\n",
       "allen      104\n",
       "keenan     103\n",
       "wr          88\n",
       "mike        87\n",
       "kupp        87\n",
       "godwin      84\n",
       "chris       81\n",
       "leaders     77\n",
       "78          70\n",
       "97          69\n",
       "88          69\n",
       "89          69\n",
       "ev          68\n",
       "hopkins     49\n",
       "team        47\n",
       "de          37"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting top 20 tokens for player - Julio\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv_def_p1 = CountVectorizer(lowercase=True, binary=False, stop_words = my_stopwords_1) \n",
    "cv_eda_p1 = cv_def_p1.fit_transform(fantasy_tweets_p1['clean_tweet'])\n",
    "print(cv_eda_p1.shape)\n",
    "print('')\n",
    "names_eda_p1 = cv_def_p1.get_feature_names()   #create list of feature names\n",
    "count_eda_p1 = np.sum(cv_eda_p1.toarray(), axis = 0) # add up feature counts \n",
    "count2_eda_p1 = count_eda_p1.tolist()  # convert numpy array to list\n",
    "count_eda_df_p1 = pd.DataFrame(count2_eda_p1, index = names_eda_p1, columns = ['count']) # create a dataframe from the list\n",
    "print('Julio Jones Tweets - Token Count')\n",
    "count_eda_df_p1.sort_values(['count'], ascending = False)[0:19]  #arrange by count instead of alphabetical (top 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 984)\n",
      "\n",
      "Will Fuller Tweets - Token Count\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fuller</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wr</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pts</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scoring</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>since</th>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balled</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>craziest</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rb</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jones</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deshaun</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christian</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccaffrey</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppr</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "fuller       390\n",
       "wr           161\n",
       "53           152\n",
       "pts          129\n",
       "scoring      127\n",
       "since        123\n",
       "balled       121\n",
       "part         120\n",
       "wk           120\n",
       "2000         120\n",
       "craziest     120\n",
       "rb            85\n",
       "best          82\n",
       "jones         63\n",
       "deshaun       59\n",
       "christian     58\n",
       "mccaffrey     58\n",
       "ppr           57\n",
       "aaron         55"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting top 20 tokens for player - Fuller\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv_def_p2 = CountVectorizer(lowercase=True, binary=False, stop_words = my_stopwords_1) \n",
    "cv_eda_p2 = cv_def_p2.fit_transform(fantasy_tweets_p2['clean_tweet'])\n",
    "print(cv_eda_p2.shape)\n",
    "print('')\n",
    "names_eda_p2 = cv_def_p2.get_feature_names()   #create list of feature names\n",
    "count_eda_p2 = np.sum(cv_eda_p2.toarray(), axis = 0) # add up feature counts \n",
    "count2_eda_p2 = count_eda_p2.tolist()  # convert numpy array to list\n",
    "count_eda_df_p2 = pd.DataFrame(count2_eda_p2, index = names_eda_p2, columns = ['count']) # create a dataframe from the list\n",
    "print('Will Fuller Tweets - Token Count')\n",
    "count_eda_df_p2.sort_values(['count'], ascending = False)[0:19]  #arrange by count instead of alphabetical (top 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment analysis among the two trending players yielded some interesting results. \n",
    "\n",
    "Julio Jones has long been considered a top player for fantasy football, so it is interesting to note that today's sentiment is near even among the net positive and net negative tweets mentioning his name. A closer look at the token counts here shows a few other top players at his positiion, along with the token 'leaders'. It could be that there is debate going on regarding this weeks rankings for the top end wide receivers and an article on rankings this week may want to highlight Julio as a conversation piece.\n",
    "\n",
    "Will Fuller has different results indicating nearly twice as many net negative tweets as positive. This is in contrast with the token counts revealing such positive words as 'balled', 'best', and in certain context, 'craziest'. The difference here could be a case of a player having an outlier performance the week prior, which if we look at the player analytics on our site, is exactly what happened. A player focused article discussing last week's performance, and what to expect going forward for this player based on our site's rest of season outlook, might attract some attention this week."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
